{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is there a corelation between the weather or the days of the week and how much I tend to watch on Netflix?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are going to analyze my Netflix viewing history from a downloaded csv file that lists the title of what I watched and the date of when I watched it. Combingin this with local weather data from an API and the days of the week will allow me to test if:\n",
    "\n",
    "* I tend to watch more on the weekends\n",
    "* Watch more when the weather is poor (ie. raining heavily)\n",
    "\n",
    "To test this I will do a hypothesis test of the frequency of things watched on Fridays, Saturdays, and Sundays ( ie. my classification of the weekend) compared to how much I watched in the week (ie. Monday-Thursday)\n",
    ">NOTE: I am classifying Friday as the weekend because I believe I probably watched more in the evening on a Friday due to usually not having a responsiblity I need to wake up for the next morning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do these test and combine these separate pieces of data. But, we first need to set up APIs to get the weather from certain days and the days of the week. \n",
    "Since the first instance from the NEtflix Viewing history csv file is dated \"7/30/16\" we need to import weather data and the days of the week from \"7/30/16\" to the last recorded day in the viewing hisotry file which is \"4/9/2022\".\n",
    ">NOTE: for the weather I am going to just use the weather data from the Sammamish, WA area (where I live) since for the most part I watch netflix at home."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to import all of the data\n",
    "##### Importing the Weather\n",
    "Getting the longitude and latitude for Sammamish.\n",
    "This will allow me to use a spearate API to get the closest weather station ID to Sammamish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sammamish latitude: 47.60553\n",
      "Sammamish longitude: -122.035555\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "f = open(\"lat.txt\", 'r')\n",
    "key = f.read()\n",
    "long_lat_url = \"http://www.mapquestapi.com/geocoding/v1/address?key=\" + key + \"&location=Sammamish\"\n",
    "request_city = requests.get(long_lat_url)\n",
    "json_city_str = request_city.text\n",
    "json_city_obj = json.loads(json_city_str)\n",
    "\n",
    "# getting latitiude and longititude of Sammamish\n",
    "city_results_list = json_city_obj[\"results\"]\n",
    "dict = city_results_list[0]\n",
    "locations_list = dict[\"locations\"]\n",
    "locations_dict = locations_list[0]\n",
    "longLat_dict = locations_dict[\"displayLatLng\"]\n",
    "latitude = longLat_dict[\"lat\"]\n",
    "longitude = longLat_dict[\"lng\"]\n",
    "\n",
    "print(\"Sammamish latitude:\", latitude)\n",
    "print(\"Sammamish longitude:\",longitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the weather stations ID using a separate API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weather Station ID: KRNT0\n"
     ]
    }
   ],
   "source": [
    "f = open(\"Weather.txt\", 'r')\n",
    "key = f.read()\n",
    "headers = {\"x-rapidapi-key\": key}\n",
    "url = \"https://meteostat.p.rapidapi.com/stations/nearby?lat=\" + str(latitude) + \"&lon=\" + str(longitude) + \"&limit=1\"\n",
    "request = requests.get(url = url, headers = headers)\n",
    "\n",
    "json_station_str = request.text\n",
    "json_station_obj = json.loads(json_station_str)\n",
    "station_list = json_station_obj[\"data\"]\n",
    "station_dict = station_list[0]\n",
    "station_id = station_dict[\"id\"]\n",
    "print(\"Weather Station ID:\", station_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now finally here we are loading the weather collected from this weather station from during the time period of 7/30/16 to 4/9/2022:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            date  tavg  tmin  tmax  prcp  snow   wdir  wspd  wpgt    pres  \\\n",
      "0     2016-07-30  19.8  15.6  25.0   0.0  None    NaN  11.2  None  1014.1   \n",
      "1     2016-07-31  18.4  14.4  22.8   0.0  None    NaN   9.1  None     NaN   \n",
      "2     2016-08-01  18.0  12.8  25.0   0.0  None    NaN   6.9  None  1018.2   \n",
      "3     2016-08-02  17.6  15.0  21.7   NaN  None    NaN   NaN  None     NaN   \n",
      "4     2016-08-03  19.2  15.6  23.9   0.0  None    NaN   NaN  None  1024.2   \n",
      "...          ...   ...   ...   ...   ...   ...    ...   ...   ...     ...   \n",
      "2075  2022-04-05   7.6   4.0  12.0   0.8  None  172.0  14.7  None  1025.3   \n",
      "2076  2022-04-06   8.8   2.0  16.0   0.0  None    6.0   9.7  None  1030.7   \n",
      "2077  2022-04-07  14.3   7.0  22.0   0.0  None  354.0   7.7  None  1021.4   \n",
      "2078  2022-04-08  10.1   7.0  15.0  10.2  None  194.0  18.2  None  1022.6   \n",
      "2079  2022-04-09   6.4   3.0   9.0   6.4  None  159.0  12.1  None  1024.6   \n",
      "\n",
      "      tsun  \n",
      "0     None  \n",
      "1     None  \n",
      "2     None  \n",
      "3     None  \n",
      "4     None  \n",
      "...    ...  \n",
      "2075  None  \n",
      "2076  None  \n",
      "2077  None  \n",
      "2078  None  \n",
      "2079  None  \n",
      "\n",
      "[2080 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# get daily weather from station 2016-07-30 through 2022-04-09\n",
    "headers = {\"x-rapidapi-key\": key}\n",
    "weather_url = \"https://meteostat.p.rapidapi.com/stations/daily?station=\"+ station_id + \"&start=2016-07-30&end=2022-04-09\"\n",
    "request_weather = requests.get(url = weather_url, headers = headers)\n",
    "json_weather_str = request_weather.text\n",
    "json_weather_obj = json.loads(json_weather_str)\n",
    "weather_df = pd.DataFrame(json_weather_obj[\"data\"])\n",
    "# weather_df.set_index(\"date\", inplace = True)\n",
    "weather_df.to_csv(\"daily_weather.csv\")\n",
    "print(weather_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing the days of the week:\n",
    "Next we need to load in the days of the week from 2016-07-30 through to 2022-04-09.\n",
    "To do this we are using the datetime library to create a dataframe with the dates within this parameter and then the corresponding day of the week\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "           Day of Week\n",
      "Date                  \n",
      "2016-07-30    Saturday\n",
      "2016-07-31      Sunday\n",
      "2016-08-01      Monday\n",
      "2016-08-02     Tuesday\n",
      "2016-08-03   Wednesday\n",
      "...                ...\n",
      "2022-04-05     Tuesday\n",
      "2022-04-06   Wednesday\n",
      "2022-04-07    Thursday\n",
      "2022-04-08      Friday\n",
      "2022-04-09    Saturday\n",
      "\n",
      "[2080 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "date_df = pd.DataFrame()\n",
    "date_df[\"Date\"] = pd.Series(pd.date_range('2016-7-30', '2022-4-9', freq='D'))\n",
    "date_df[\"Day of Week\"] = date_df['Date'].dt.day_name()\n",
    "# change to string so I can compare easily\n",
    "\n",
    "change_ser = pd.Series(list(string))\n",
    "\n",
    "for value in range(len(date_df[\"Date\"])):\n",
    "    temp = str(date_df[\"Date\"][value]).split(\" \")\n",
    "    string = temp[0]\n",
    "    change_ser[value] = string\n",
    "date_df[\"Date\"] = change_ser\n",
    "\n",
    "print(type(date_df[\"Date\"][1]))\n",
    "date_df.set_index(\"Date\", inplace = True)\n",
    "date_df.to_csv(\"Days_of_The_Week.csv\")\n",
    "print(date_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data\n",
    "Now that we have loaded all of the data we need to clean the files in order to accurately compute data and make hypotheses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning the Weather DataFrame\n",
    "First we are going to clean the weather dataframe.\n",
    "Converting the temperatures to farenheit and then deleting the columns with more than 50 percent of teh values missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Date  tavg  tmin  tmax  prcp   wdir       wspd     pres\n",
      "0     2016-07-30  19.8  15.6  25.0   0.0    NaN  11.200000  1014.10\n",
      "1     2016-07-31  18.4  14.4  22.8   0.0    NaN   9.100000  1016.15\n",
      "2     2016-08-01  18.0  12.8  25.0   0.0    NaN   6.900000  1018.20\n",
      "3     2016-08-02  17.6  15.0  21.7   0.0    NaN   8.566667  1021.20\n",
      "4     2016-08-03  19.2  15.6  23.9   0.0    NaN  10.233333  1024.20\n",
      "...          ...   ...   ...   ...   ...    ...        ...      ...\n",
      "2075  2022-04-05   7.6   4.0  12.0   0.8  172.0  14.700000  1025.30\n",
      "2076  2022-04-06   8.8   2.0  16.0   0.0    6.0   9.700000  1030.70\n",
      "2077  2022-04-07  14.3   7.0  22.0   0.0  354.0   7.700000  1021.40\n",
      "2078  2022-04-08  10.1   7.0  15.0  10.2  194.0  18.200000  1022.60\n",
      "2079  2022-04-09   6.4   3.0   9.0   6.4  159.0  12.100000  1024.60\n",
      "\n",
      "[2080 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import utils\n",
    "# Cleaning and Interpolating\n",
    "weather_df.replace(\"\", np.NaN, inplace = True)\n",
    "length_df = len(weather_df)\n",
    "for value in weather_df:\n",
    "    ser = weather_df[value].copy()\n",
    "    for i in range(len(ser)):\n",
    "        # if col is something you can interpolate\n",
    "        if(value == \"tavg\", \"tmin\", \"tmax\", \"prcp\", \"wdir\", \"wspd\", \"pres\" and ser.isnull()):\n",
    "            ser.interpolate(inplace = True)\n",
    "    weather_df[value] = ser\n",
    "    # removing columns with more than 50 percent of values missing\n",
    "    count = weather_df[value].isnull().sum()\n",
    "    if count > (length_df / 2):\n",
    "        del weather_df[value]\n",
    "\n",
    "# # converting to imperial\n",
    "# avg_temp_ser = weather_df[\"tavg\"].copy()\n",
    "# min_temp_ser = weather_df[\"tmin\"].copy()\n",
    "# max_temp_ser = weather_df[\"tmax\"].copy()\n",
    "# for value in range(len(weather_df)):\n",
    "#     avg_temp_ser[value] = utils.convert_temp(avg_temp_ser[value])\n",
    "#     min_temp_ser[value] = utils.convert_temp(min_temp_ser[value])\n",
    "#     max_temp_ser[value] = utils.convert_temp(max_temp_ser[value])\n",
    "# weather_df[\"tavg\"] = avg_temp_ser\n",
    "# weather_df[\"tmin\"] = min_temp_ser\n",
    "# weather_df[\"tmax\"] = max_temp_ser\n",
    "weather_df = weather_df.rename({\"date\": \"Date\"}, axis = \"columns\")\n",
    "print(weather_df)\n",
    "weather_df.set_index(\"Date\", inplace=True)\n",
    "weather_df.to_csv(\"cleaned_daily_weather.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning the Date Column of the Netflix Dataframe\n",
    "This will be converting the dates in this colunn from the format `4/9/22` to `2022-04-09`.\n",
    "This will allow us the combine the other two data sets easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       2022-04-09\n",
      "1       2022-04-09\n",
      "2       2022-04-08\n",
      "3       2022-04-08\n",
      "4       2022-04-05\n",
      "           ...    \n",
      "2468    2016-08-01\n",
      "2469    2016-08-01\n",
      "2470    2016-07-30\n",
      "2471    2016-07-30\n",
      "2472    2016-07-30\n",
      "Name: Date, Length: 2473, dtype: object\n"
     ]
    }
   ],
   "source": [
    "netflix_df = pd.read_csv(\"NetflixViewingHistory_project.csv\")\n",
    "\n",
    "date_ser = netflix_df[\"Date\"].copy()\n",
    "\n",
    "for date in range(len(date_ser)):\n",
    "    temp = date_ser[date].split(\"/\")\n",
    "    year = \"20\" + temp[2]\n",
    "    month = temp[0]\n",
    "    if(len(temp[0]) == 1):\n",
    "        month = \"0\" + month\n",
    "    day = temp[1]\n",
    "    if(len(temp[1]) == 1):\n",
    "        day = \"0\" + day\n",
    "    date_ser[date] = year + \"-\" + month + \"-\" + day\n",
    "netflix_df[\"Date\"] = date_ser\n",
    "netflix_df.to_csv(\"cleaned_Netflix_Viewing_History.csv\")\n",
    "print(netflix_df[\"Date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Joining The Days Of The Week And The Weather For That Day:\n",
    "We are doing this since each of these dataframes have keys of the date, which can only have one instance, and since it will make it easier to compare and visualize this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            tavg  tmin  tmax  prcp   wdir       wspd     pres Day of Week\n",
      "Date                                                                     \n",
      "2016-07-30  19.8  15.6  25.0   0.0    NaN  11.200000  1014.10    Saturday\n",
      "2016-07-31  18.4  14.4  22.8   0.0    NaN   9.100000  1016.15      Sunday\n",
      "2016-08-01  18.0  12.8  25.0   0.0    NaN   6.900000  1018.20      Monday\n",
      "2016-08-02  17.6  15.0  21.7   0.0    NaN   8.566667  1021.20     Tuesday\n",
      "2016-08-03  19.2  15.6  23.9   0.0    NaN  10.233333  1024.20   Wednesday\n",
      "...          ...   ...   ...   ...    ...        ...      ...         ...\n",
      "2022-04-05   7.6   4.0  12.0   0.8  172.0  14.700000  1025.30     Tuesday\n",
      "2022-04-06   8.8   2.0  16.0   0.0    6.0   9.700000  1030.70   Wednesday\n",
      "2022-04-07  14.3   7.0  22.0   0.0  354.0   7.700000  1021.40    Thursday\n",
      "2022-04-08  10.1   7.0  15.0  10.2  194.0  18.200000  1022.60      Friday\n",
      "2022-04-09   6.4   3.0   9.0   6.4  159.0  12.100000  1024.60    Saturday\n",
      "\n",
      "[2080 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "merged_weather_dayWeek_df = weather_df.merge(date_df, on = [\"Date\"], how= \"inner\")\n",
    "print(merged_weather_dayWeek_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['2016-07-30', '2016-07-31', '2016-08-01', '2016-08-02', '2016-08-03',\n",
      "       '2016-08-04', '2016-08-05', '2016-08-06', '2016-08-07', '2016-08-08',\n",
      "       ...\n",
      "       '2022-03-31', '2022-04-01', '2022-04-02', '2022-04-03', '2022-04-04',\n",
      "       '2022-04-05', '2022-04-06', '2022-04-07', '2022-04-08', '2022-04-09'],\n",
      "      dtype='object', name='Date', length=2080)\n",
      "0       2022-04-09\n",
      "1       2022-04-09\n",
      "2       2022-04-08\n",
      "3       2022-04-08\n",
      "4       2022-04-05\n",
      "           ...    \n",
      "2468    2016-08-01\n",
      "2469    2016-08-01\n",
      "2470    2016-07-30\n",
      "2471    2016-07-30\n",
      "2472    2016-07-30\n",
      "Name: Date, Length: 2473, dtype: object\n"
     ]
    }
   ],
   "source": [
    "freq_list = [0] * len(merged_weather_dayWeek_df)\n",
    "freq_watched_ser = pd.Series(freq_list)\n",
    "\n",
    "freq_df = pd.DataFrame(columns = [\"Date\", \"Things Watched\"])\n",
    "freq_df[\"Things Watched\"] = freq_watched_ser\n",
    "freq_df[\"Date\"] = date_df.index\n",
    "freq_df[\"Things Watched\"] = freq_watched_ser\n",
    "freq_df.set_index(\"Date\", inplace = True)\n",
    "# print(freq_df)\n",
    "freq_df.index = freq_df.index.astype(str)\n",
    "# print(type(freq_df.index[1]))\n",
    "# for date in netflix_df[\"Date\"]:\n",
    "#     freq_df[date][\"Things Watched\"] += 1\n",
    "\n",
    "print(freq_df.index)\n",
    "print(netflix_df[\"Date\"])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "05e5263a5b3128ff67a7c8b075ff25752474a0d33381b4218d5af07966bbb998"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
